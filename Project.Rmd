---
title: "STATS 765 Project Milestone 3 -- Car Crash"
author: "Neil He"
date: '2022-05-16'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(Hmisc)
library(ggplot2)
library(ranger)
library(xgboost)
df <- read_csv('crash data.csv', na=c('Null', 'NA',''))
```

## 1. Goal

The main idea for our project is to find out what are the key factors that cause car crashes in New Zealand and what cause the different level of crashes. We decide focus more on compare the difference of key factors between Fatal,Serious crashes and Minor, Non-Injury crashes.

## 2. Data Source

We get all the data we need from the NZ Transport Agency Open Data Port. On the website, we can find out that five results show up. We only need the Crash Analysis System(CAS) to do the rest of our task. The data can be downloaded as CSV, KML, Shapefile, and GeoJSON format, but we need a CSV file that will be good to go. The file we got is named Crash_AnalysisSystem(CAS)\_data.csv, which is a terrible name for programming. Thus, we change it to crash_data.csv.

As a result, we have 72 attributes in the data set, and we will not use all of them. Thus, we decide to drop some of those, and some contain missing values. If those columns are not necessary or related to our goal, we will settle them, but on the other hand, if columns are going to affect our result and contain missing values, we need to fill them.

All the data we retrieved in Appendix 1.1

## 3. Data Processing

The mean idea is to choose those columns that we only need to use for analysis. Here we can see after tidying the data set. The original data set have 72 attributes, Now We only have 11 essential attributes left. Here is a quick view of the data set I modified and named as df2. The full code will be in Appendix 1.2

```{r include=FALSE}
df2 <- select(df,c(OBJECTID, 
                   urban,
                   crashYear,
                   directionRoleDescription,
                   light,
                   region,
                   speedLimit,
                   roadLane,
                   roadSurface,
                   weatherA,
                   crashSeverity
))
```

```{r echo=TRUE}
length(names(df)) # initial attributes 
head(df2)
```

Here we got the data set we need for the next step. However, there is still some missing value in it. Thus, we need to find a way to impute them. And this is how its looks like. For the region, we can't do anything more, so we just use filter to select those not equal to NA.

```{r echo=TRUE}
colSums(is.na(df2))
```

For the speedLimit, we are going to use the `impute` function from `Hmisc()` package to use the median number to impute the N/A value

```{r echo=TRUE}
df2$speedLimit=impute(df2$speedLimit,median) #use median to replace missing value
```

For the region and directionRoleDescription we decide just omit them since the potion of them are too small in the entire data set. We have total 776878 rows.

```{r echo=TRUE}
nrow(df2) # 
```

```{r echo=TRUE}
df3 <- na.omit(df2)
colSums(is.na(df3))
```

Now we handled all the missing values. When we read in the data set, we transfer all the 'Null' to N/A and treat it as a missing value, since if we want to check 'Null' row by row, that would be very expensive. After that, since we total got 776878 rows, there are too many missing values in weathers, and we cannot impute them. Thus, we choose to omit all of them.

## 4. Data Exploration

In this part, we will focus on using graphs to illustrate the relation between crash severity and different attributes. We will first show the number of crashes in different severity. And present as percentage.

```{r echo=TRUE}
t1 <- table(df3$crashSeverity)
t1
prop.table(t1)*100
```

### Severity

Next, we will look around which area in New Zealand have the highest crash number by decreasing order. And also the different severity in every region.

```{r echo=TRUE}
ggplot(data=df3) + 
  geom_bar(mapping=aes(x=fct_infreq(region)))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(df3,aes(x=crashSeverity, group = region)) + geom_bar() +  facet_wrap(~region) +theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

### Light

Next, we will look some weather and sunshine condition when car crash happened.Full code in Appendix 1.4

```{r echo=TRUE}
knitr::kable(table(df3$light))
```

```{r echo=FALSE}
light <- ggplot(df3,aes(x=crashSeverity, group = region)) + geom_bar() +  facet_wrap(~light) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title='Histgram with Sunshine condition and four type of crash')

# For Fatal Crash and Serious Crash

light1 <- df3 %>% filter(crashSeverity == 'Fatal Crash' | crashSeverity=='Serious Crash') %>% ggplot(aes(x=fct_infreq(crashSeverity), group = region)) + geom_bar() +  
  facet_grid(~light) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title='Histgram with Sunshine condition and two type of crash - Fatal and Serious')

# For Minor and Non-Injury Crash

light2 <- df3 %>% filter(crashSeverity == 'Minor Crash' | crashSeverity=='Non-Injury Crash') %>% ggplot(aes(x=fct_infreq(crashSeverity), group = region)) + geom_bar() +  
  facet_grid(~light) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title='Histgram with Sunshine condition and two type of crash - Minor and Non-Injury')
```

```{r echo=TRUE}
light
light1
light2
```

### Weather

Next, we will look at the weather attribute. Full code in Appendix 1.4

```{r echo=FALSE}
weather <-df3 %>%
    ggplot(aes(x=weatherA))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='Histgram with weather and four type of crash')

weather1 <- df3 %>% filter(crashSeverity == 'Fatal Crash' | crashSeverity=='Serious Crash') %>%
    ggplot(aes(x=weatherA))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='Histgram with weather and two type of crash - Fatal and Serious')

weather2 <- df3 %>% filter(crashSeverity == 'Minor Crash' | crashSeverity=='Non-Injury Crash') %>%
    ggplot(aes(x=weatherA))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='Histgram with weather and two type of crash - Minor and Non-Injury')
```

```{r echo=TRUE}
weather
weather1
weather2
```

### Year

```{r echo=FALSE}
year <- df3 %>%
    ggplot(aes(x=crashYear))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='histgram with years and crash type')

year1 <- df3 %>% filter(crashSeverity == 'Fatal Crash' | crashSeverity=='Serious Crash') %>%
    ggplot(aes(x=crashYear))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='histgram with years and crash type')


year2 <- df3 %>% filter(crashSeverity == 'Minor Crash' | crashSeverity=='Non-Injury Crash')%>%
    ggplot(aes(x=crashYear))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='histgram with years and crash type')

```

```{r echo=TRUE}
year
year1
year2
```

### Findings

-   Auckland area has the highest car crash rate. Waikato, Canterbury, and Wellington Region fellows.
-   From the data count, we can see the data set category by severity is not balanced. Fatal Crash and Serious Crash only take 0.933 and 5.73 percent out of all the crashes. This could cause some problems when we are doing further investigation.
-   In the weather and Light diagram, the pattern is very similar.

## 5. Analytical Plan

We are going to try a few models during this milestone. We are not very sure about which attributes contributed to the crash most. Thus, we want to build models to find out. We are going to use the same train and test data.

Since our data set from sections 2 and 3 already prove that our data set is not very balanced. Thus, we need to use a stratified sampling strategy.

We decide to not using the Non-Injury Crash data in the further since we don't really care about those cases. We are going to more focus on Minor Crashes vs Fatal+Serious Crashes vs  Thus, we label them into 0 and 1 respectively.

Full Code in Appendix 1.5 & 1.6 & 1.7.

Here we tried Random Forest.

```{r echo=FALSE}
df4 <- df3 %>% filter(crashSeverity!='Non-Injury Crash')

# twolevel, fatal as 3 and serious as 2, non as 0 and minor as 1
#df3$twolevel <- ifelse(df3$crashSeverity == "Non-Injury Crash", 0, 1)
#df3$twolevel[df3$crashSeverity == "Serious Crash"] <- 2
#df3$twolevel[df3$crashSeverity == "Fatal Crash"] <- 3

# Change to Minor as 0, Serious and Fatal as 1
df4$twolevel <- ifelse(df4$crashSeverity == "Minor Crash", 0, 1)

df4$twolevel=as.integer(df4$twolevel)

#split into train and test
test_set <- df4 %>% group_by(crashSeverity) %>% slice_sample(prop = .05)
train_set <- df4 %>% anti_join(test_set)
#dim(test_set) # size of test set
#dim(train_set) # size of train set


train_modelframe<-model.frame(crashSeverity~.,data=select(train_set,-twolevel,-OBJECTID))
# make matrix
train_X<-model.matrix(crashSeverity~.,train_modelframe)

#test
test_modelframe<-model.frame(crashSeverity~.,data=select(test_set, -twolevel,-OBJECTID)) 
test_X<-model.matrix(crashSeverity~., test_modelframe)
```

```{r echo=TRUE}
table(df4$twolevel)

dim(test_set)

dim(train_set)
```
### Random Forest

```{r echo=TRUE}
rf <- ranger(factor(twolevel)~.,data=select(train_set, -crashSeverity,-OBJECTID),importance='permutation', classification=TRUE)

```

```{r echo=TRUE}
yhat_forest_w <- predict(rf,test_set)$predictions
paste('The accuracy is',sum(yhat_forest_w==test_set$twolevel)/length(test_set$twolevel))
sort(rf$variable.importance,decreasing=TRUE)
```

### XGBOOST
```{r echo=FALSE}
crash_xgb <- xgboost(data=train_X, label=train_set$twolevel, nrounds=15, verbose=0,objective='binary:logistic')
crash_xgb_cv <- xgb.cv(data = train_X, label = train_set$twolevel, nrounds = 30, nfold = 10, objective = "binary:logistic",early_stopping_rounds = 3)
yhat_xgb <- round(predict(crash_xgb, test_X))
```
```{r echo=TRUE}
head(xgb.importance(model=crash_xgb))
```

## 6. Discussion

In this milestone, we have tried the random forest model and got the initial result with an accuracy score of around 0.7. We also think using `rpart` to build a decision tree model or a neural network will work for our case.

This time we find out our data set is imbalanced. Thus, we decide not to use Non Injury crashes data, since we are not really care about them and cut that part of data off can help us to balance the data. In the result of our model, we use importance to check what caused the car crash. The chart shows that Speed Limit is the key factor contribute to the serious and fatal crashes.

## Appendix

### 1.1

```{r echo=TRUE}
library(tidyverse)
library(Hmisc)
```

```{r echo=TRUE ,eval=FALSE}
df <- read_csv('crash data.csv')
head(df)
```

### 1.2

```{r echo=TRUE ,eval=FALSE}
df2 <- select(df,c(OBJECTID, 
                   urban,
                   crashYear,
                   directionRoleDescription,
                   light,
                   region,
                   speedLimit,
                   roadLane,
                   roadSurface,
                   weatherA,
                   crashSeverity
))
colSums(is.na(df2))
```

### 1.4

```{r echo=TRUE,eval=FALSE}
light <- ggplot(df3,aes(x=crashSeverity, group = region)) + geom_bar() +  facet_wrap(~light) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# For Fatal Crash and Serious Crash

light1 <- df3 %>% filter(crashSeverity == 'Fatal Crash' | crashSeverity=='Serious Crash') %>% ggplot(aes(x=fct_infreq(crashSeverity), group = region)) + geom_bar() +  
  facet_grid(~light) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# For Minor and Non-Injury Crash

light2 <- df3 %>% filter(crashSeverity == 'Minor Crash' | crashSeverity=='Non-Injury Crash') %>% ggplot(aes(x=fct_infreq(crashSeverity), group = region)) + geom_bar() +  
  facet_grid(~light) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

weather <-df3 %>%
    ggplot(aes(x=weatherA))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='Histgram with weather and four type of crash')

weather1 <- df3 %>% filter(crashSeverity == 'Fatal Crash' | crashSeverity=='Serious Crash') %>%
    ggplot(aes(x=weatherA))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='Histgram with weather and two type of crash - Fatal and Serious')

weather2 <- df3 %>% filter(crashSeverity == 'Minor Crash' | crashSeverity=='Non-Injury Crash') %>%
    ggplot(aes(x=weatherA))+
    geom_bar(stat="count")+
    facet_wrap(~crashSeverity)+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    labs(title='Histgram with weather and two type of crash - Minor and Non-Injury')
```

### 1.5

```{r echo=TRUE,eval=FALSE}
df4 <- df3 %>% filter(crashSeverity!='Non-Injury Crash')

# twolevel, fatal as 3 and serious as 2, non as 0 and minor as 1
#df3$twolevel <- ifelse(df3$crashSeverity == "Non-Injury Crash", 0, 1)
#df3$twolevel[df3$crashSeverity == "Serious Crash"] <- 2
#df3$twolevel[df3$crashSeverity == "Fatal Crash"] <- 3

# Change to Minor as 0, Serious and Fatal as 1
df4$twolevel <- ifelse(df4$crashSeverity == "Minor Crash", 0, 1)

df4$twolevel=as.integer(df4$twolevel)

#split into train and test
test_set <- df4 %>% group_by(crashSeverity) %>% slice_sample(prop = .05)
train_set <- df4 %>% anti_join(test_set)
#dim(test_set) # size of test set
#dim(train_set) # size of train set


train_modelframe<-model.frame(crashSeverity~.,data=select(train_set,-twolevel,-OBJECTID))
# make matrix
train_X<-model.matrix(crashSeverity~.,train_modelframe)

#test
test_modelframe<-model.frame(crashSeverity~.,data=select(test_set, -twolevel,-OBJECTID)) 
test_X<-model.matrix(crashSeverity~., test_modelframe)
```

### 1.6
```{r echo=TRUE,eval=FALSE}
rf <- ranger(factor(twolevel)~.,data=select(train_set, -crashSeverity,-OBJECTID),importance='permutation', classification=TRUE)
yhat_forest_w <- predict(rf,test_set)$predictions
paste('The accuracy is',sum(yhat_forest_w==test_set$twolevel)/length(test_set$twolevel))
sort(rf$variable.importance,decreasing=TRUE)
```
### Logistical Regression

```{r echo=TRUE,eval=FALSE}
library(ISLR)

logistic.fit <- glm(twolevel~.,family = 'binomial',data = select(train_set,-crashSeverity,-OBJECTID))

summary(logistic.fit)

model2 <- step(object = logistic.fit, trace = 0)
summary(model2)

anova(object = model2,test = "Chisq")

yhat_forest <- predict(model2,select(test_set, -OBJECTID), type = 'response')
```

```{r echo=TRUE,eval=FALSE}
crash_xgb <- xgboost(data=train_X, label=train_set$twolevel, nrounds=15, verbose=0,objective='binary:logistic')
crash_xgb_cv <- xgb.cv(data = train_X, label = train_set$twolevel, nrounds = 30, nfold = 10, objective = "binary:logistic",early_stopping_rounds = 3)
yhat_xgb <- round(predict(crash_xgb, test_X))
head(xgb.importance(model=crash_xgb))
```
